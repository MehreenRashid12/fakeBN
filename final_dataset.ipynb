{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKbgopaOvbjc85QLjKVNU/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXBTxB7eh8gj"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import spacy"
      ],
      "metadata": {
        "id": "j_eZjTmai-WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LtyS_B-ooYyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth_seeker = '/content/drive/MyDrive/fakeBN/data/Truth_Seeker_Model_Dataset.csv'\n",
        "truth_seeker_ml = '/content/drive/MyDrive/fakeBN/data/Features_For_Traditional_ML_Techniques.csv'\n",
        "truth_seeker_timestamp = '/content/drive/MyDrive/fakeBN/data/Truth_Seeker_Model_Dataset_With_TimeStamps.csv'\n",
        "significant_events =  '/content/drive/MyDrive/fakeBN/data/on_this_day_events_2009_2022.csv'\n",
        "\n",
        "data_ts = pd.read_csv(truth_seeker)\n",
        "data_ml = pd.read_csv(truth_seeker_ml)\n",
        "data_timestamp = pd.read_csv(truth_seeker_timestamp)\n",
        "data_significant_events = pd.read_csv(significant_events)"
      ],
      "metadata": {
        "id": "nCbwKfNCoZkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ml_merged = data_ml.merge(data_timestamp[['tweet', 'timestamp']], how='left', on='tweet')\n",
        "data_ml_merged = pd.concat([data_ml_merged, data_ml.drop('tweet', axis=1)], axis=1)\n",
        "data_ml_merged.dropna(subset=['timestamp'], inplace=True)\n",
        "data_ml_merged['timestamp'] = pd.to_datetime(data_ml_merged['timestamp'])\n",
        "data_significant_events['date'] = pd.to_datetime(data_significant_events['date']).dt.date"
      ],
      "metadata": {
        "id": "IrUD8fODonxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = data_ml_merged.copy()\n",
        "\n",
        "nlp_lg = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Function to check if a tweet is similar to significant events\n",
        "def is_similar(row):\n",
        "    start_date = (row['timestamp'] - pd.DateOffset(months=1)).date()\n",
        "    end_date = row['timestamp'].date()\n",
        "    filtered_events = data_significant_events[\n",
        "        (data_significant_events['date'] >= start_date) &\n",
        "        (data_significant_events['date'] <= end_date)\n",
        "    ]\n",
        "    tweet_doc = nlp_lg(row['tweet'])\n",
        "    for event in filtered_events['event']:\n",
        "        event_doc = nlp_lg(event)\n",
        "        if tweet_doc.similarity(event_doc) >= 0.8:\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "final_data['matches_significant_event'] = final_data.apply(is_similar, axis=1)\n",
        "\n",
        "final_data['timestamp'] = pd.to_datetime(final_data['timestamp'])\n",
        "\n",
        "\n",
        "final_data['day'] = final_data['timestamp'].dt.dayofweek\n",
        "final_data['month'] = final_data['timestamp'].dt.month\n",
        "final_data['hour'] = final_data['timestamp'].dt.hour\n",
        "final_data['minute'] = final_data['timestamp'].dt.minute\n",
        "final_data['quarter'] = final_data['timestamp'].dt.quarter\n",
        "final_data['isWeekend'] = final_data['timestamp'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
        "final_data['day'] = final_data['timestamp'].dt.dayofweek\n",
        "final_data['month'] = final_data['timestamp'].dt.month\n",
        "final_data['hour'] = final_data['timestamp'].dt.hour\n",
        "final_data['minute'] = final_data['timestamp'].dt.minute\n",
        "final_data['quarter'] = final_data['timestamp'].dt.quarter\n",
        "final_data['is_weekend'] = final_data['timestamp'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
        "\n",
        "final_data.to_csv('/content/drive/MyDrive/fakeBN/data/final_data.csv', index=False)"
      ],
      "metadata": {
        "id": "jXM2SAZaxEaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}